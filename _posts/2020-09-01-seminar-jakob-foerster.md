---
layout: post
title:  "[Seminar] 'Self-Play and Zero-Shot (Human-AI) Coordination (in Hanabi)' by Jakob Foerster"
categories: Seminar
tags: [seminar, hanabi, hci, coordination, self-play]
excerpt: "<ul>
<li><b>Title:</b> Self-Play and Zero-Shot (Human-AI) Coordination (in Hanabi)</li>
<li><b>Speaker:</b> Jakob Foerster (University of Toronto)</li> 
<li><b>Time and date:</b> 4pm to 5pm, September 9th, 2020 (Wednesday)</li>
<li><b>Room:</b> <a href='https://us02web.zoom.us/j/88924608310'>Virtual (Zoom)</a></li>
</ul>"
mathjax: false
---

* content
{:toc}

<ul>
<li><b>Title:</b> Self-Play and Zero-Shot (Human-AI) Coordination (in Hanabi)</li>
<li><b>Speaker:</b> Jakob Foerster (University of Toronto)</li> 
<li><b>Time and date:</b> 4pm to 5pm, September 9th, 2020 (Wednesday)</li>
<li><b>Room:</b> <a href='https://us02web.zoom.us/j/88924608310'>Virtual (Zoom)</a></li>
</ul>

The Game AI Research Group is glad to announce a (virtual) talk by Jakob Foerster on Wednesday Sept 9 at 16:00.

All welcome (especially students), no pre-booking required 

## Abstract

In recent years we have seen fast progress on a number of zero-sum benchmark problems in AI, e.g. Go, Poker and Dota. In contrast, success in the real world requires humans to collaborate and communicate with others, in settings that are, at least partially, cooperative. Recently, the card game Hanabi has been established as a new benchmark environment to fill this gap. In particular, Hanabi is interesting to humans since it is entirely focused on theory of mind, i.e., the ability to reason over the intentions, beliefs and point of view of other agents when observing their actions. This is particularly important in applications such as communication, assistive technologies and autonomous driving.

In this talk we provide an update on recent progress in this area. We start out with novel state-of-the-art methods for the self-play setting. Next, we introduce the zero-shot coordination setting as a new frontier for multi-agent research and, finally, introduce Other-Play as a novel learning algorithm which biases learning towards more human compatible policies.

## Bio

Jakob Foerster received a CIFAR AI chair in 2019 and is starting as an Assistant Professor at the University of Toronto and the Vector Institute in fall 2020. During his PhD at the University of Oxford, he helped bring deep multi-agent reinforcement learning to the forefront of AI research and interned at Google Brain, OpenAI, and DeepMind. He has since been working as a research scientist at Facebook AI Research in California, where he will continue advancing the field up to his move to Toronto. He was the lead organizer of the first Emergent Communication (EmeCom) workshop at NeurIPS in 2017, which he has helped organize ever since.
